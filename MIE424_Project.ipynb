{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIE424_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHHafe9oBNJn"
      },
      "source": [
        "# MIE424 Project\n",
        "\n",
        "## 1. Load the Adult dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAB6xPc9A9WD",
        "outputId": "2d03f051-d2dd-43fc-a532-bc204ef713e3"
      },
      "source": [
        "!git clone https://github.com/mlohaus/SearchFair.git\n",
        "%cd SearchFair"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SearchFair'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 86 (delta 32), reused 74 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n",
            "/content/SearchFair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0c0JuKqBYkW"
      },
      "source": [
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "IiXEhiXIBhBO",
        "outputId": "b283edd0-1198-4dc5-9653-865dbca1b157"
      },
      "source": [
        "# Load data into pandas DataFrame\n",
        "dataset = pd.read_csv('data/adult/adult.csv')\n",
        "\n",
        "# Drop fnlwgt, education, education-num, capital-gain, capital-loss as Lohaus et al do\n",
        "dataset = dataset.drop(columns=['fnlwgt', 'education', 'capital-gain', 'capital-loss'])\n",
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48837</th>\n",
              "      <td>39</td>\n",
              "      <td>Private</td>\n",
              "      <td>13</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48838</th>\n",
              "      <td>64</td>\n",
              "      <td>?</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>?</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48839</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48840</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>13</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48841</th>\n",
              "      <td>35</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>60</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48842 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age         workclass  ...  native-country income\n",
              "0       39         State-gov  ...   United-States  <=50K\n",
              "1       50  Self-emp-not-inc  ...   United-States  <=50K\n",
              "2       38           Private  ...   United-States  <=50K\n",
              "3       53           Private  ...   United-States  <=50K\n",
              "4       28           Private  ...            Cuba  <=50K\n",
              "...    ...               ...  ...             ...    ...\n",
              "48837   39           Private  ...   United-States  <=50K\n",
              "48838   64                 ?  ...   United-States  <=50K\n",
              "48839   38           Private  ...   United-States  <=50K\n",
              "48840   44           Private  ...   United-States  <=50K\n",
              "48841   35      Self-emp-inc  ...   United-States   >50K\n",
              "\n",
              "[48842 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "FYOa3KBXFxXt",
        "outputId": "3cf2936e-be1e-41da-e4f9-894d85ad1a26"
      },
      "source": [
        "def replaceWithOneHot(df, col_name):\n",
        "    # Takes in a pandas dataframe and replaces column with name col_name\n",
        "    # with multiple columns of its one-hot encoding\n",
        "    one_hots = pd.get_dummies(dataset[col_name], prefix=col_name)\n",
        "    df = df.drop(columns =[col_name])\n",
        "    df = df.join(one_hots)\n",
        "    return df \n",
        "\n",
        "## Onehot categorical variables\n",
        "#for feature in ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']:\n",
        "#    dataset = replaceWithOneHot(dataset, feature);\n",
        "\n",
        "#Format below features in dataset to be binary based on Lohaus' get_real_data.py\n",
        "dataset.loc[dataset['age'] > 37, 'age'] = 1\n",
        "dataset.loc[dataset['age'] != 1, 'age'] = 0\n",
        "\n",
        "dataset.loc[dataset['workclass'] == 'Private', 'workclass'] = 1\n",
        "dataset.loc[dataset['workclass'] != 1, 'workclass'] = 0\n",
        "\n",
        "dataset.loc[dataset['education-num'] == 9, 'education-num'] = 1\n",
        "dataset.loc[dataset['education-num'] != 1, 'education-num'] = 0\n",
        "\n",
        "dataset.loc[dataset['marital-status'] == \"Married-civ-spouse\", 'marital-status'] = 1\n",
        "dataset.loc[dataset['marital-status'] != 1, 'marital-status'] = 0\n",
        "\n",
        "dataset.loc[dataset['occupation'] == \"Craft-repair\", 'occupation'] = 1\n",
        "dataset.loc[dataset['occupation'] != 1, 'occupation'] = 0\n",
        "\n",
        "dataset.loc[dataset['relationship'] == \"Not-in-family\", 'relationship'] = 1\n",
        "dataset.loc[dataset['relationship'] != 1, 'relationship'] = 0\n",
        "\n",
        "dataset.loc[dataset['race'] == \"White\", 'race'] = 1\n",
        "dataset.loc[dataset['race'] != 1, 'race'] = 0\n",
        "\n",
        "dataset.loc[dataset['hours-per-week'] > 40, 'hours-per-week'] = 1\n",
        "dataset.loc[dataset['hours-per-week'] != 1, 'hours-per-week'] = 0\n",
        "\n",
        "dataset.loc[dataset['native-country'] == \"United-States\", 'native-country'] = 1\n",
        "dataset.loc[dataset['native-country'] != 1, 'native-country'] = 0\n",
        "\n",
        "#Replace 'Male' with 1 and 'Female' with 0 in sex column\n",
        "dataset.loc[dataset['sex'] == 'Male', 'sex'] = 1\n",
        "dataset.loc[dataset['sex'] == 'Female', 'sex'] = -1\n",
        "\n",
        "#replace '>50K' with 1 and '<=50K' with 0 in income column\n",
        "dataset.loc[dataset['income'] == '>50K', 'income'] = 1\n",
        "dataset.loc[dataset['income'] == '<=50K', 'income'] = -1\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48837</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48838</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48839</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48840</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48841</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48842 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age workclass  education-num marital-status occupation relationship  \\\n",
              "0        1         0              0              0          0            1   \n",
              "1        1         0              0              1          0            0   \n",
              "2        1         1              1              0          0            1   \n",
              "3        1         1              0              1          0            0   \n",
              "4        0         1              0              1          0            0   \n",
              "...    ...       ...            ...            ...        ...          ...   \n",
              "48837    1         1              0              0          0            1   \n",
              "48838    1         0              1              0          0            0   \n",
              "48839    1         1              0              1          0            0   \n",
              "48840    1         1              0              0          0            0   \n",
              "48841    0         0              0              1          0            0   \n",
              "\n",
              "      race sex  hours-per-week native-country income  \n",
              "0        1   1               0              1     -1  \n",
              "1        1   1               0              1     -1  \n",
              "2        1   1               0              1     -1  \n",
              "3        0   1               0              1     -1  \n",
              "4        0  -1               0              0     -1  \n",
              "...    ...  ..             ...            ...    ...  \n",
              "48837    1  -1               0              1     -1  \n",
              "48838    0   1               0              1     -1  \n",
              "48839    1   1               1              1     -1  \n",
              "48840    0   1               0              1     -1  \n",
              "48841    1   1               1              1      1  \n",
              "\n",
              "[48842 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsvmOhIUNzJQ"
      },
      "source": [
        "# Lohaus uses a random 10000 points for training, validation, and the rest for testing\n",
        "# Since adult.csv is already shuffled, use the first 10000 rows as training and rest as testing\n",
        "\n",
        "train_dataset = dataset.head(10000)\n",
        "test_dataset = dataset.tail(len(dataset) - 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGPaMY_EQd7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "def get_adult_data(sens_attribute = 'sex',load_data_size=None):\n",
        "  \"\"\"Load the Adult dataset.\n",
        "  Source: UCI Machine Learning Repository.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  load_data_size: int\n",
        "      The number of points to be loaded. If None, returns all data points unshuffled.\n",
        "\n",
        "  Returns\n",
        "  ---------\n",
        "  X: numpy array\n",
        "      The features of the datapoints with shape=(number_points, number_features).\n",
        "  y: numpy array\n",
        "      The class labels of the datapoints with shape=(number_points,).\n",
        "  s: numpy array\n",
        "      The binary sensitive attribute of the datapoints with shape=(number_points,).\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  def mapping(tuple):\n",
        "    # age, 37\n",
        "    tuple['age'] = 1 if tuple['age'] > 37 else 0\n",
        "    # workclass\n",
        "    tuple['workclass'] = 'NonPrivate' if tuple['workclass'] != 'Private' else 'Private'\n",
        "    # edunum\n",
        "    tuple['education-num'] = 1 if tuple['education-num'] > 9 else 0\n",
        "    # maritial statue\n",
        "    tuple['marital-status'] = \"Marriedcivspouse\" if tuple['marital-status'] == \"Married-civ-spouse\" else \"nonMarriedcivspouse\"\n",
        "    # occupation\n",
        "    tuple['occupation'] = \"Craftrepair\" if tuple['occupation'] == \"Craft-repair\" else \"NonCraftrepair\"\n",
        "    # relationship\n",
        "    tuple['relationship'] = \"NotInFamily\" if tuple['relationship'] == \"Not-in-family\" else \"InFamily\"\n",
        "    # race\n",
        "    tuple['race'] = 'NonWhite' if tuple['race'] != \"White\" else \"White\"\n",
        "    # sex\n",
        "    tuple['sex'] = 'Female' if tuple['sex'] != \"Male\" else 'Male'\n",
        "    # hours per week\n",
        "    tuple['hours-per-week'] = 1 if tuple['hours-per-week'] > 40 else 0\n",
        "    # native country\n",
        "    tuple['native-country'] = \"US\" if tuple['native-country'] == \"United-States\" else \"NonUS\"\n",
        "    return tuple\n",
        "\n",
        "\n",
        "  df = dataset\n",
        "  df = df.apply(mapping, axis=1)\n",
        "\n",
        "  if sens_attribute == 'sex':\n",
        "    sensitive_attr_map = {'Male': 1, 'Female': -1}\n",
        "  elif sens_attribute == 'race':\n",
        "    sensitive_attr_map = {'White': 1, 'NonWhite': -1}\n",
        "  label_map = {'>50K': 1, '<=50K': -1}\n",
        "\n",
        "  if sens_attribute == 'sex':\n",
        "    x_vars = ['age','workclass','education-num','marital-status','occupation','relationship','race','hours-per-week','native-country']\n",
        "  elif sens_attribute == 'race':\n",
        "    x_vars = ['age','workclass','education-num','marital-status','occupation','relationship','sex','hours-per-week','native-country']\n",
        "\n",
        "  s = df[sens_attribute].map(sensitive_attr_map).astype(int)\n",
        "  y = df['income'].map(label_map).astype(int)\n",
        "\n",
        "\n",
        "  x = pd.DataFrame(data=None)\n",
        "  for x_var in x_vars:\n",
        "    x = pd.concat([x, pd.get_dummies(df[x_var],prefix=x_var, drop_first=False)], axis=1)\n",
        "\n",
        "  X = x.to_numpy()\n",
        "  s = s.to_numpy()\n",
        "  y = y.to_numpy()\n",
        "\n",
        "  if load_data_size is not None: # Don't shuffle if all data is requested\n",
        "      # shuffle the data\n",
        "      perm = list(range(0, len(y)))\n",
        "      shuffle(perm)\n",
        "      X = X[perm]\n",
        "      y = y[perm]\n",
        "      s = s[perm]\n",
        "\n",
        "      print(\"Loading only %d examples from the data\" % load_data_size)\n",
        "      X = X[:load_data_size]\n",
        "      y = y[:load_data_size]\n",
        "      s = s[:load_data_size]\n",
        "\n",
        "  X = X[:, (X != 0).any(axis=0)]\n",
        "\n",
        "  return X, y, s\n",
        "\n",
        "def normalize(x):\n",
        "\t# scale to [-1, 1]\n",
        "\tx_ = (x - x.min()) / (x.max() - x.min()) * 2 - 1\n",
        "\treturn x_"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZwUp46MCX8W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUAX-dZ6ESo_"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPZesAQRPqBX"
      },
      "source": [
        "## 2. Implement baseline models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INV5lNE9PuPP"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.base import BaseEstimator\n",
        "import sklearn.metrics.pairwise as kernels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "import random"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAPO8nTeqKhi"
      },
      "source": [
        "class BaselineModel(BaseEstimator):\n",
        "    def __init__(self, l2_beta=0.001, kernel='linear', gamma=0.1, loss_name='hinge', lambda_max=1, max_iter=3000, solver='SCS', verbose=False,reason_points=0.5):\n",
        "\n",
        "        self.l2_beta = l2_beta # Regularization parameter beta for the l2 regularization\n",
        "        self.kernel = kernel # The SVM kernel to be used.. Options:['linear','rbf','poly']\n",
        "        self.gamma = gamma # If kernel='rbf', gamma to be kernel width, If kernel='poly', gamma to be degree.\n",
        "        self.loss_name = loss_name # Loss function to be used. Options:['hinge','logistic','squared','exponential']\n",
        "        self.lambda_max = lambda_max # The max lambda value for the start of the binary search.\n",
        "        self.max_iter = max_iter # The number of iterations.\n",
        "        self.solver = solver # The solver to be used by cvxpy. Options:['SCS','ECOS'].\n",
        "        self.verbose = verbose # If true, Overrides the default of hiding solver output.\n",
        "        self.reason_points = reason_points # The ratio of points used as reasonable points for the similarity-based approach of SearchFair.\n",
        "\n",
        "    def fit(self, x_train, y_train,s_train):\n",
        "        \"\"\"Fits a baseline SVM model on the given training data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x_train: numpy array\n",
        "            The features of the training data with shape=(number_points,number_features).\n",
        "        y_train: numpy array\n",
        "            The class labels of the training data with shape=(number_points,).\n",
        "      \n",
        "        Returns\n",
        "        ----------\n",
        "        self: object\n",
        "        \"\"\"\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.s_train = s_train\n",
        "        \n",
        "        self._preprocess()\n",
        "\n",
        "        lambda_min, lambda_max = 0, self.lambda_max\n",
        "\n",
        "        self._construct_problem()\n",
        "                \n",
        "        self._optimize()\n",
        "            \n",
        "        criterion = False\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        \"\"\"Predict the label of test data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x_test: numpy array\n",
        "            The features of the test data with shape=(number_points,number_features).\n",
        "        Returns\n",
        "        ----------\n",
        "        y_hat: numpy array\n",
        "            The predicted class labels with shape=(number_points,).\n",
        "        \"\"\"\n",
        "        kernel_matr = self.kernel_function(x_test, self.x_train[self.reason_pts_index])\n",
        "        y_hat = np.dot(self.coef_, np.transpose(kernel_matr))\n",
        "        return np.sign(y_hat)\n",
        "\n",
        "    def _preprocess(self):\n",
        "        \"\"\"Setting the attributes loss_func and kernel_function.\n",
        "        \"\"\"\n",
        "        self.coef_ = None\n",
        "        if self.loss_name == 'logistic':\n",
        "            self.loss_func = lambda z: cp.logistic(-z)\n",
        "        elif self.loss_name == 'hinge':\n",
        "            self.loss_func = lambda z: cp.pos(1.0 - z)\n",
        "        elif self.loss_name == 'squared':\n",
        "            self.loss_func = lambda z: cp.square(-z)\n",
        "        elif self.loss_name == 'exponential':\n",
        "            self.loss_func = lambda z: cp.exp(-z)\n",
        "        else:\n",
        "            print('Using default loss: hinge loss.')\n",
        "            self.loss_func = lambda z: cp.pos(1.0 - z)\n",
        "\n",
        "        if self.kernel == 'rbf':\n",
        "            self.kernel_function = lambda X, Y: kernels.rbf_kernel(X, Y, self.gamma)\n",
        "        elif self.kernel == 'poly':\n",
        "            self.kernel_function = lambda X, Y: kernels.polynomial_kernel(X, Y, degree=self.gamma)\n",
        "        elif self.kernel == 'linear':\n",
        "            self.kernel_function = lambda X, Y: kernels.linear_kernel(X, Y) + 1\n",
        "        else:\n",
        "            self.kernel_function = kernel\n",
        "\n",
        "        # Choose random reasonable points\n",
        "        self.nmb_pts = self.x_train.shape[0]\n",
        "        if self.reason_points <= 1:\n",
        "            self.reason_pts_index = list(range(int(self.nmb_pts * self.reason_points)))\n",
        "        else:\n",
        "            self.reason_pts_index = list(range(self.reason_points))\n",
        "        self.nmb_reason_pts = len(self.reason_pts_index)\n",
        "\n",
        "    def _construct_problem(self):\n",
        "        \"\"\" Construct the cvxpy minimization problem.\n",
        "        \"\"\"\n",
        "\n",
        "        # Variable to optimize\n",
        "        self.params = cp.Variable((len(self.reason_pts_index), 1))\n",
        "        # Parameter for Kernel Matrix\n",
        "        self.kernel_matrix = cp.Parameter(shape=(self.x_train.shape[0], len(self.reason_pts_index)))\n",
        "        self.bias = cp.Variable()\n",
        "\n",
        "         \n",
        "        # Loss Function to Minimize (with Regularization)\n",
        "        \n",
        "        self.loss = self.loss = cp.sum(self.loss_func(cp.multiply(self.y_train.reshape(-1, 1), self.kernel_matrix @ self.params))) + self.l2_beta * self.nmb_pts * cp.square(\n",
        "                cp.norm(self.params, 2))\n",
        "        \n",
        "        # Final Problem Formulization\n",
        "        self.prob = cp.Problem(cp.Minimize(self.loss))\n",
        "\n",
        "    def _optimize(self):\n",
        "        \"\"\"Conduct the optimization of the created problem by using ECOS or SCS\n",
        "        with cvxpy. \n",
        "        \"\"\"\n",
        "        self.K_sim = self.kernel_function(self.x_train, self.x_train[self.reason_pts_index])\n",
        "        self.kernel_matrix.value = self.K_sim\n",
        "\n",
        "        if self.solver == 'SCS':\n",
        "            self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "        elif self.solver == 'ECOS':\n",
        "            try:\n",
        "                self.prob.solve(solver=cp.ECOS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "            except Exception as e:\n",
        "                self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "    \n",
        "        self.coef_ = self.params.value.squeeze()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1OCk8WcqKho"
      },
      "source": [
        "## 3. Implement Basic Test Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD53vBvvqKhu"
      },
      "source": [
        "class TestProcedure():\n",
        "    def __init__(self,model):\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def BuildDataset(self,sens_attribute,train_size = 1200):\n",
        "        x_data, y_data, s_data = get_adult_data(sens_attribute,load_data_size=None)\n",
        "        # Train Test split. Here, we choose a small number to reduce running time.\n",
        "        train_size = 1200\n",
        "        x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)\n",
        "        \n",
        "        self.X_train = x_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "        self.X_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.s_train = s_train\n",
        "        self.s_test = s_test\n",
        "\n",
        "                \n",
        "    def BuildModel(self):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        self.model.fit(self.X_train,self.y_train,self.s_train)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        build_time = end_time - start_time\n",
        "        \n",
        "        return build_time\n",
        "        \n",
        "    def RunBasicTest(self,sens_attribute):\n",
        "        self.BuildDataset(sens_attribute)\n",
        "        build_time = self.BuildModel()\n",
        "        predictions = self.model.predict(self.X_test)\n",
        "        prediction_accuracy = np.equal(self.y_test, predictions).mean()\n",
        "        \n",
        "        ddp,deo = self.compute_fairness_measures(predictions, self.y_test ,self.s_test)\n",
        "        results = {\"BuildTime\":build_time,\"PredictionAccuracy\":prediction_accuracy,\"DDP\":ddp,\"DEO\":deo}\n",
        "        self.PrintResults(results)\n",
        "        return results\n",
        "        \n",
        "    def compute_fairness_measures(self, y_predicted, y_true, sens_attr):\n",
        "        \"\"\"Compute value of demographic parity and equality of opportunity for given predictions.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        sens_attr: numpy array\n",
        "            The sensitive labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ----------\n",
        "        DDP: float\n",
        "            The difference of demographic parity.\n",
        "        DEO: float\n",
        "            The difference of equality of opportunity.\n",
        "        \"\"\"\n",
        "        \n",
        "        positive_rate_prot = self.get_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        positive_rate_unprot = self.get_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        true_positive_rate_prot = self.get_true_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        true_positive_rate_unprot = self.get_true_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        DDP = positive_rate_unprot - positive_rate_prot\n",
        "        DEO = true_positive_rate_unprot - true_positive_rate_prot\n",
        "\n",
        "        return DDP, DEO\n",
        "\n",
        "    def get_positive_rate(self, y_predicted, y_true):\n",
        "        \"\"\"Compute the positive rate for given predictions of the class label.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ---------\n",
        "        pr: float\n",
        "            The positive rate.\n",
        "        \"\"\"\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true.astype(int), y_predicted.astype(int)).ravel()\n",
        "        pr = (tp+fp) / (tp+fp+tn+fn)\n",
        "        return pr\n",
        "\n",
        "    def get_true_positive_rate(self, y_predicted, y_true):\n",
        "        \"\"\"Compute the true positive rate for given predictions of the class label.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ---------\n",
        "        tpr: float\n",
        "            The true positive rate.\n",
        "        \"\"\"\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true.astype(int), y_predicted.astype(int)).ravel()\n",
        "        tpr = tp / (tp+fn)\n",
        "        return tpr\n",
        "        \n",
        "    def PrintResults(self,results):\n",
        "      print(\"Kernel Type:\",self.model.kernel)\n",
        "      print(\"Loss Func:\",self.model.loss_name)\n",
        "      print(\"Run Time:\",round(results['BuildTime'],4),\"seconds\")\n",
        "      print(\"Prediction Accuracy:\",str(round(results['PredictionAccuracy']*100,4)),\"%\")\n",
        "      print(\"DDP Score:\",str(round(results['DDP'],4)))\n",
        "      print(\"DEO Score:\",str(round(results['DEO'],4)))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcxB5j-2qKhv",
        "outputId": "a857abca-6735-4c32-f4b4-a008d61c8e26"
      },
      "source": [
        "baseline_linear_hinge = BaselineModel(kernel='linear',loss_name='hinge')\n",
        "baseline_1_tester = TestProcedure(baseline_linear_hinge)\n",
        "baseline_1_test_results = baseline_1_tester.RunBasicTest(sens_attribute='sex')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit\n",
            "Preprocess\n",
            "Construct\n",
            "Optimize\n",
            "Predict\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 2.342 seconds\n",
            "Prediction Accuracy: 80.767 %\n",
            "DDP Score: 0.0957\n",
            "DEO Score: 0.0149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBUhzonZqKhx",
        "outputId": "f33cd1b4-010f-4fee-f588-ca16ce10a020"
      },
      "source": [
        "baseline_rbf_hinge = BaselineModel(kernel='rbf',loss_name='hinge')\n",
        "baseline_2_tester = TestProcedure(baseline_rbf_hinge)\n",
        "baseline_2_test_results = baseline_2_tester.RunBasicTest(sens_attribute='race')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit\n",
            "Preprocess\n",
            "Construct\n",
            "Optimize\n",
            "Predict\n",
            "Kernel Type: rbf\n",
            "Loss Func: hinge\n",
            "Run Time: 2.7336 seconds\n",
            "Prediction Accuracy: 81.5814 %\n",
            "DDP Score: 0.0894\n",
            "DEO Score: 0.0509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7X28nvXX4sN"
      },
      "source": [
        "## 4. GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ktdFfs1ecY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8b7d23-fdc0-41aa-bd94-52e72df988db"
      },
      "source": [
        "# regularization parameter beta\n",
        "sens_attribute = 'sex'\n",
        "\n",
        "grid_search_model = BaselineModel()\n",
        "\n",
        "beta_params = [0.0001, 0.001, 0.01] # For Linear Kernel\n",
        "gamma_params = [0.01, 0.1, 1] # For RBF Kernel\n",
        "kernel_params = ['linear','rbf']\n",
        "cv_params = {'l2_beta': beta_params,'gamma': gamma_params,'kernel':kernel_params}\n",
        "\n",
        "x_data, y_data, s_data = get_adult_data(sens_attribute,load_data_size=None)\n",
        "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=1200, shuffle=True)\n",
        "\n",
        "grid_clf = GridSearchCV(grid_search_model,cv_params, cv=4, n_jobs=1, scoring='accuracy')\n",
        "grid_clf.fit(x_train, y_train, s_train = s_train)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, error_score=nan,\n",
              "             estimator=BaselineModel(gamma=0.1, kernel='linear', l2_beta=0.001,\n",
              "                                     lambda_max=1, loss_name='hinge',\n",
              "                                     max_iter=3000, reason_points=0.5,\n",
              "                                     solver='SCS', verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'gamma': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf'],\n",
              "                         'l2_beta': [0.0001, 0.001, 0.01]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tb_Vl-QO_G8",
        "outputId": "97a62e9a-60ed-4b7f-fe66-85b5f5d05f70"
      },
      "source": [
        "grid_clf.cv_results_"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.94513726, 0.93955191, 0.90660055, 0.83508706, 0.86360677,\n",
              "        0.84023309, 0.84569343, 0.84799782, 0.8198127 , 1.81358155,\n",
              "        1.91670354, 1.92958538, 1.25409619, 1.2327923 , 1.26333014,\n",
              "        1.95298656, 1.96494754, 1.94357387]),\n",
              " 'mean_score_time': array([0.00536474, 0.00408999, 0.00392254, 0.0038592 , 0.00230948,\n",
              "        0.0023284 , 0.00236988, 0.00234032, 0.0030729 , 0.01120504,\n",
              "        0.01096574, 0.0142192 , 0.00729553, 0.01055566, 0.01173043,\n",
              "        0.00750128, 0.00728623, 0.00729338]),\n",
              " 'mean_test_score': array([0.805     , 0.805     , 0.805     , 0.805     , 0.805     ,\n",
              "        0.805     , 0.805     , 0.805     , 0.805     , 0.79666667,\n",
              "        0.79666667, 0.79666667, 0.805     , 0.805     , 0.805     ,\n",
              "        0.805     , 0.805     , 0.805     ]),\n",
              " 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'linear',\n",
              "                    'linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
              "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_l2_beta': masked_array(data=[0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.01,\n",
              "                    0.01, 0.01, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
              "                    0.001, 0.01, 0.01, 0.01],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[1500, 3000, 5000, 1500, 3000, 5000, 1500, 3000, 5000,\n",
              "                    1500, 3000, 5000, 1500, 3000, 5000, 1500, 3000, 5000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'kernel': 'linear', 'l2_beta': 0.0001, 'max_iter': 1500},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.0001, 'max_iter': 3000},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.0001, 'max_iter': 5000},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.001, 'max_iter': 1500},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.001, 'max_iter': 3000},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.001, 'max_iter': 5000},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.01, 'max_iter': 1500},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.01, 'max_iter': 3000},\n",
              "  {'kernel': 'linear', 'l2_beta': 0.01, 'max_iter': 5000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.0001, 'max_iter': 1500},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.0001, 'max_iter': 3000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.0001, 'max_iter': 5000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.001, 'max_iter': 1500},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.001, 'max_iter': 3000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.001, 'max_iter': 5000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.01, 'max_iter': 1500},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.01, 'max_iter': 3000},\n",
              "  {'kernel': 'rbf', 'l2_beta': 0.01, 'max_iter': 5000}],\n",
              " 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1, 16, 16, 16,  1,  1,  1,  1,  1,\n",
              "         1], dtype=int32),\n",
              " 'split0_test_score': array([0.8175, 0.8175, 0.8175, 0.8175, 0.8175, 0.8175, 0.8175, 0.8175,\n",
              "        0.8175, 0.8   , 0.8   , 0.8   , 0.8175, 0.8175, 0.8175, 0.8175,\n",
              "        0.8175, 0.8175]),\n",
              " 'split1_test_score': array([0.8025, 0.8025, 0.8025, 0.8025, 0.8025, 0.8025, 0.8025, 0.8025,\n",
              "        0.8025, 0.795 , 0.795 , 0.795 , 0.8025, 0.8025, 0.8025, 0.8025,\n",
              "        0.8025, 0.8025]),\n",
              " 'split2_test_score': array([0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795,\n",
              "        0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795, 0.795]),\n",
              " 'std_fit_time': array([0.05394596, 0.06683732, 0.04755925, 0.01184676, 0.03991045,\n",
              "        0.01994149, 0.01113612, 0.00629185, 0.00481806, 0.30447641,\n",
              "        0.36844544, 0.3192264 , 0.09960325, 0.15249923, 0.08197325,\n",
              "        0.61524322, 0.60768929, 0.64874483]),\n",
              " 'std_score_time': array([2.18461923e-03, 2.38847830e-03, 2.30230808e-03, 2.27548726e-03,\n",
              "        6.60702962e-05, 3.69761519e-05, 3.54466773e-05, 5.53873950e-05,\n",
              "        1.20192596e-03, 4.74236814e-03, 4.47337846e-03, 4.78783207e-03,\n",
              "        3.25400360e-05, 4.52890226e-03, 5.20633978e-03, 2.08677177e-04,\n",
              "        4.60344782e-05, 7.98455085e-06]),\n",
              " 'std_test_score': array([0.00935414, 0.00935414, 0.00935414, 0.00935414, 0.00935414,\n",
              "        0.00935414, 0.00935414, 0.00935414, 0.00935414, 0.00235702,\n",
              "        0.00235702, 0.00235702, 0.00935414, 0.00935414, 0.00935414,\n",
              "        0.00935414, 0.00935414, 0.00935414])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjlXeTgjRNkH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}