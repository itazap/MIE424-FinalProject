{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Balanced_Copy_of_MIE424_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itazap/MIE424-FinalProject/blob/main/Balanced_Copy_of_MIE424_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHHafe9oBNJn"
      },
      "source": [
        "# MIE424 Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktA8StDVa56K"
      },
      "source": [
        "## Section 4. Load and Explore the Adult Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0c0JuKqBYkW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from random import shuffle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAB6xPc9A9WD",
        "outputId": "9c930a11-9889-45b5-bb16-c894c6c86023"
      },
      "source": [
        "!git clone https://github.com/mlohaus/SearchFair.git\n",
        "%cd SearchFair"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SearchFair'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 86 (delta 32), reused 74 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n",
            "/content/SearchFair\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "IiXEhiXIBhBO",
        "outputId": "b8ae1f89-5409-4fec-95db-f5ecad7129f7"
      },
      "source": [
        "# Load data into pandas DataFrame\n",
        "dataset = pd.read_csv('data/adult/adult.csv')\n",
        "data50minus = dataset[dataset[\"income\"].str.contains(\"<=50K\")].iloc[:11687]\n",
        "data50plus = dataset[dataset[\"income\"].str.contains(\">50K\")].iloc[:11687]\n",
        "databalanced = pd.concat([data50minus, data50plus])\n",
        "dataset = databalanced.sample(frac=1).reset_index(drop=True)\n",
        "# Drop fnlwgt, education, education-num, capital-gain, capital-loss as Lohaus et al do\n",
        "dataset = dataset.drop(columns=['fnlwgt', 'education', 'capital-gain', 'capital-loss'])\n",
        "dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>Private</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>60</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>Private</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>32</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>Private</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>Germany</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23369</th>\n",
              "      <td>39</td>\n",
              "      <td>Private</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23370</th>\n",
              "      <td>52</td>\n",
              "      <td>Private</td>\n",
              "      <td>5</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>Puerto-Rico</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23371</th>\n",
              "      <td>61</td>\n",
              "      <td>?</td>\n",
              "      <td>13</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>?</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23372</th>\n",
              "      <td>51</td>\n",
              "      <td>Private</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23373</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>52</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23374 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  workclass  education-num  ... hours-per-week native-country income\n",
              "0       36    Private             14  ...             60  United-States   >50K\n",
              "1       32    Private             10  ...             32  United-States   >50K\n",
              "2       42    Private             10  ...             40        Germany  <=50K\n",
              "3       54  Local-gov             13  ...             40  United-States   >50K\n",
              "4       18          ?              9  ...             25  United-States  <=50K\n",
              "...    ...        ...            ...  ...            ...            ...    ...\n",
              "23369   39    Private             14  ...             50  United-States   >50K\n",
              "23370   52    Private              5  ...             25    Puerto-Rico  <=50K\n",
              "23371   61          ?             13  ...             40  United-States  <=50K\n",
              "23372   51    Private              9  ...             40  United-States  <=50K\n",
              "23373   38    Private             13  ...             52  United-States   >50K\n",
              "\n",
              "[23374 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGPaMY_EQd7"
      },
      "source": [
        "def build_adult_data(dataset=dataset,sens_attribute = 'sex',load_data_size=None):\n",
        "  \"\"\"Build the Adult dataset.\n",
        "  Source: UCI Machine Learning Repository.\n",
        "  All Binary Mappings are defined in Lohaus' Too Relaxed To Be Fair research.\n",
        "  We have kept the exact same mapping to make for clean comparisons. \n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  load_data_size: int\n",
        "      The number of points to be loaded. If None, returns all data points unshuffled.\n",
        "      If other than None, returns load_data_size shuffled.\n",
        "\n",
        "  Returns\n",
        "  ---------\n",
        "  X: numpy array\n",
        "      The feature input matrix after a binary mapping of attributes.\n",
        "      Shape=(number_data_points, number_features)\n",
        "  y: numpy array\n",
        "      The classification labels (matrix) after a binary mapping of attributes.\n",
        "      Shape=(number_data_points,).\n",
        "  s: numpy array\n",
        "      The sensitive feature vector after a binary mapping of attributes. \n",
        "      Shape=(number_data_points,).\n",
        "  \"\"\"\n",
        "  \n",
        "  def binary_mapping(tuple):\n",
        "    # 'age'- Binary Cut-off: 37\n",
        "    tuple['age'] = 1 if tuple['age'] > 37 else 0\n",
        "    # 'workclass'- Binary Translation to Private/NonPrivate\n",
        "    tuple['workclass'] = 'NonPrivate' if tuple['workclass'] != 'Private' else 'Private'\n",
        "    # 'education-num'- Binary Cut-off: 9\n",
        "    tuple['education-num'] = 1 if tuple['education-num'] > 9 else 0\n",
        "    # 'maritial-status'- Binary Translation to Married-civ-spouse/nonMarriedcivspouse\n",
        "    tuple['marital-status'] = \"Marriedcivspouse\" if tuple['marital-status'] == \"Married-civ-spouse\" else \"nonMarriedcivspouse\"\n",
        "    # 'occupation'- Binary Translation to Craft-repair/NonCraftrepair\n",
        "    tuple['occupation'] = \"Craftrepair\" if tuple['occupation'] == \"Craft-repair\" else \"NonCraftrepair\"\n",
        "    # 'relationship'- Binary Translation to InFamily/Not-in-family\n",
        "    tuple['relationship'] = \"NotInFamily\" if tuple['relationship'] == \"Not-in-family\" else \"InFamily\"\n",
        "    # 'race'- Binary Translation to White/NonWhite\n",
        "    tuple['race'] = 'NonWhite' if tuple['race'] != \"White\" else \"White\"\n",
        "    # 'sex'- Binary Translation to Male/Female\n",
        "    tuple['sex'] = 'Female' if tuple['sex'] != \"Male\" else 'Male'\n",
        "    # 'hours-per-week'- Binary Cut-off: 40\n",
        "    tuple['hours-per-week'] = 1 if tuple['hours-per-week'] > 40 else 0\n",
        "    # 'native-country'- Binary Translation to United-States/NonUS\n",
        "    tuple['native-country'] = \"US\" if tuple['native-country'] == \"United-States\" else \"NonUS\"\n",
        "    \n",
        "    return tuple\n",
        "\n",
        "  df = dataset\n",
        "  df = df.apply(binary_mapping, axis=1)\n",
        "\n",
        "  # Convert Binary Mapping of Sensitive Attribute to {1,-1}\n",
        "  if sens_attribute == 'sex':\n",
        "    sensitive_attr_map = {'Male': 1, 'Female': -1}\n",
        "    x_vars = ['age','workclass','education-num','marital-status','occupation','relationship','race','hours-per-week','native-country']\n",
        "  elif sens_attribute == 'race':\n",
        "    sensitive_attr_map = {'White': 1, 'NonWhite': -1}\n",
        "    x_vars = ['age','workclass','education-num','marital-status','occupation','relationship','sex','hours-per-week','native-country']\n",
        "  \n",
        "  s = df[sens_attribute].map(sensitive_attr_map).astype(int)\n",
        "\n",
        "  # Convert Binary Mapping of Label Attribute to {1,-1}\n",
        "  label_map = {'>50K': 1, '<=50K': -1}\n",
        "  y = df['income'].map(label_map).astype(int)\n",
        "\n",
        "  # Build Input Matrix (Feature Set) as a proper DataFrame\n",
        "  x = pd.DataFrame(data=None)\n",
        "  for x_var in x_vars:\n",
        "    x = pd.concat([x, pd.get_dummies(df[x_var],prefix=x_var, drop_first=False)], axis=1)\n",
        "\n",
        "  # Return as numpy objects: Matrix/Vectors\n",
        "  X = x.to_numpy()\n",
        "  s = s.to_numpy()\n",
        "  y = y.to_numpy()\n",
        "\n",
        "  if load_data_size is not None:\n",
        "      # Shuffle the data only if data_size is specified (Random detail from Paper code)\n",
        "      perm = list(range(0, len(y)))\n",
        "      shuffle(perm)\n",
        "      X = X[perm][:load_data_size]\n",
        "      y = y[perm][:load_data_size]\n",
        "      s = s[perm][:load_data_size]\n",
        "\n",
        "  # X = X[:, (X != 0).any(axis=0)]\n",
        "\n",
        "  return X, y, s\n",
        "\n",
        "def normalize(x):\n",
        "\t# scale to [-1, 1]\n",
        "\tx_ = (x - x.min()) / (x.max() - x.min()) * 2 - 1\n",
        "\treturn x_"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUAX-dZ6ESo_"
      },
      "source": [
        "# Test\n",
        "# build_adult_data(sens_attribute='race',load_data_size=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPZesAQRPqBX"
      },
      "source": [
        "## Section 5.1 Implement Baseline Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INV5lNE9PuPP"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn.metrics.pairwise as kernels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, GroupShuffleSplit\n",
        "\n",
        "import cvxpy as cp"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAPO8nTeqKhi"
      },
      "source": [
        "class BaselineModel(BaseEstimator):\n",
        "    def __init__(self, l2_beta=0.001, kernel='linear', gamma=0.1, loss_name='hinge', lambda_max=1, max_iter=3000, solver='SCS', verbose=False,reason_points=0.5):\n",
        "\n",
        "        self.l2_beta = l2_beta # Regularization parameter beta for the l2 regularization\n",
        "        self.kernel = kernel # The SVM kernel to be used.. Options:['linear','rbf','poly']\n",
        "        self.gamma = gamma # If kernel='rbf', gamma to be kernel width, If kernel='poly', gamma to be degree.\n",
        "        self.loss_name = loss_name # Loss function to be used. Options:['hinge','logistic','squared','exponential']\n",
        "        self.lambda_max = lambda_max # The max lambda value for the start of the binary search.\n",
        "        self.max_iter = max_iter # The number of iterations.\n",
        "        self.solver = solver # The solver to be used by cvxpy. Options:['SCS','ECOS'].\n",
        "        self.verbose = verbose # If true, Overrides the default of hiding solver output.\n",
        "        self.reason_points = reason_points # The ratio of points used as reasonable points for the similarity-based approach of SearchFair.\n",
        "\n",
        "    def fit(self, x_train, y_train,s_train):\n",
        "\n",
        "        # Set class variables\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.s_train = s_train\n",
        "        \n",
        "        # Must call preprocess() after the datapoint size is given\n",
        "        self._preprocess()\n",
        "        # Construct the CVXPY problem\n",
        "        self._construct_problem()\n",
        "        # Optimize with given settings \n",
        "        self._optimize()\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def _preprocess(self):\n",
        "       \n",
        "        # Initialize the coef_ array as a class variable using cvxpy's built-in loss functions\n",
        "        self.coef_ = None\n",
        "\n",
        "        # Generate loss function based on the given loss_name\n",
        "        if self.loss_name == 'logistic':\n",
        "          self.loss_func = lambda z: cp.logistic(-z)\n",
        "        elif self.loss_name == 'hinge':\n",
        "          self.loss_func = lambda z: cp.pos(1.0 - z)\n",
        "        elif self.loss_name == 'squared':\n",
        "          self.loss_func = lambda z: cp.square(-z)\n",
        "        elif self.loss_name == 'exponential':\n",
        "          self.loss_func = lambda z: cp.exp(-z)\n",
        "        else:\n",
        "          self.loss_func = lambda z: cp.pos(1.0 - z) # Use Hinge-Loss unless specified otherwise\n",
        "\n",
        "        if self.kernel == 'rbf':\n",
        "          self.kernel_function = lambda X, Y: kernels.rbf_kernel(X, Y, self.gamma)\n",
        "        elif self.kernel == 'poly':\n",
        "          self.kernel_function = lambda X, Y: kernels.polynomial_kernel(X, Y, degree=self.gamma)\n",
        "        elif self.kernel == 'linear':\n",
        "            self.kernel_function = lambda X, Y: kernels.linear_kernel(X, Y) + 1\n",
        "        else:\n",
        "            self.kernel_function = kernel\n",
        "\n",
        "\n",
        "        # Choose random reasonable points\n",
        "        self.nmb_pts = len(self.s_train)\n",
        "        if self.reason_points <= 1:\n",
        "          self.reason_pts_index = list(range(int(self.nmb_pts * self.reason_points)))\n",
        "        else:\n",
        "          self.reason_pts_index = list(range(self.reason_points))\n",
        "        self.nmb_reason_pts = len(self.reason_pts_index)\n",
        "\n",
        "    def _construct_problem(self):\n",
        "\n",
        "        # Variable to optimize\n",
        "        self.params = cp.Variable((len(self.reason_pts_index), 1))\n",
        "        # Parameter for Kernel Matrix\n",
        "        self.kernel_matrix = cp.Parameter(shape=(self.x_train.shape[0], len(self.reason_pts_index)))\n",
        "        \n",
        "        self.bias = cp.Variable()\n",
        "\n",
        "        # Loss Function to Minimize (with Regularization)\n",
        "        self.loss = (1 / self.nmb_pts) * cp.sum(self.loss_func(cp.multiply(self.y_train.reshape(-1, 1), self.kernel_matrix @ self.params))) + self.l2_beta * cp.square(cp.norm(self.params, 2))\n",
        "        \n",
        "        # Final Problem Formulization\n",
        "        self.prob = cp.Problem(cp.Minimize(self.loss))\n",
        "\n",
        "    def _optimize(self):\n",
        "\n",
        "        self.K_sim = self.kernel_function(self.x_train, self.x_train[self.reason_pts_index])\n",
        "        self.kernel_matrix.value = self.K_sim\n",
        "\n",
        "        if self.solver == 'SCS':\n",
        "            self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "        elif self.solver == 'ECOS':\n",
        "            try:\n",
        "                self.prob.solve(solver=cp.ECOS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "            except Exception as e:\n",
        "                self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=self.verbose, warm_start=True)\n",
        "    \n",
        "        self.coef_ = self.params.value.squeeze()\n",
        "    \n",
        "    def predict(self, x_test):\n",
        "        kernel_matrix = self.kernel_function(x_test, self.x_train[self.reason_pts_index])\n",
        "        # Calculate Estimates\n",
        "        y_hat = np.dot(self.coef_, np.transpose(kernel_matrix))\n",
        "        \n",
        "        return np.sign(y_hat)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1OCk8WcqKho"
      },
      "source": [
        "## Section 5.2 Implement Testing Procedure with Fairness Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD53vBvvqKhu"
      },
      "source": [
        "class TestProcedure():\n",
        "    def __init__(self,model):\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def BuildDataset(self,sens_attribute,dataset=dataset,train_size = 1200):\n",
        "        self.sens_attribute = sens_attribute\n",
        "\n",
        "        # Build the Adult Dataset\n",
        "        x_data, y_data, s_data = build_adult_data(dataset,sens_attribute,load_data_size=None)\n",
        "        \n",
        "        # Train Test split size.\n",
        "        train_size = 1200\n",
        "        \n",
        "        # Split data into train and test.\n",
        "        x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)\n",
        "        \n",
        "        self.X_train = x_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "        self.X_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        self.s_train = s_train\n",
        "        self.s_test = s_test\n",
        "                \n",
        "    def BuildModel(self):\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        self.model.fit(self.X_train,self.y_train,self.s_train)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        build_time = end_time - start_time\n",
        "        \n",
        "        return build_time\n",
        "        \n",
        "    def RunTest(self,sens_attribute,dataset=dataset):\n",
        "        self.BuildDataset(sens_attribute,dataset=dataset)\n",
        "        build_time = self.BuildModel()\n",
        "        predictions = self.model.predict(self.X_test)\n",
        "        prediction_accuracy = np.equal(self.y_test, predictions).mean()\n",
        "        \n",
        "        ddp,deo = self.compute_fairness_measures(predictions, self.y_test ,self.s_test)\n",
        "        results = {\"BuildTime\":build_time,\"PredictionAccuracy\":prediction_accuracy,\"DDP\":ddp,\"DEO\":deo}\n",
        "        self.PrintResults(results)\n",
        "        return results\n",
        "        \n",
        "    def compute_fairness_measures(self, y_predicted, y_true, sens_attr):\n",
        "        positive_rate_prot = self.get_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        positive_rate_unprot = self.get_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        true_positive_rate_prot = self.get_true_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        true_positive_rate_unprot = self.get_true_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        DDP = positive_rate_unprot - positive_rate_prot\n",
        "        DEO = true_positive_rate_unprot - true_positive_rate_prot\n",
        "\n",
        "        return DDP, DEO\n",
        "\n",
        "    def get_positive_rate(self, y_predicted, y_true):\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true.astype(int), y_predicted.astype(int)).ravel()\n",
        "        pr = (tp+fp) / (tp+fp+tn+fn)\n",
        "        return pr\n",
        "\n",
        "    def get_true_positive_rate(self, y_predicted, y_true):\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true.astype(int), y_predicted.astype(int)).ravel()\n",
        "        tpr = tp / (tp+fn)\n",
        "        return tpr\n",
        "        \n",
        "    def PrintResults(self,results):\n",
        "      print(\"Sensitive Attribute:\",self.sens_attribute)\n",
        "      print(\"Kernel Type:\",self.model.kernel)\n",
        "      print(\"Loss Func:\",self.model.loss_name)\n",
        "      print(\"Run Time:\",round(results['BuildTime'],4),\"seconds\")\n",
        "      print(\"Prediction Accuracy:\",str(round(results['PredictionAccuracy']*100,4)),\"%\")\n",
        "      print(\"DDP Score:\",str(round(results['DDP'],4)))\n",
        "      print(\"DEO Score:\",str(round(results['DEO'],4)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcxB5j-2qKhv",
        "outputId": "b70f3e4b-2283-4fab-e9d8-f3f7de4dba63"
      },
      "source": [
        "baseline_linear_hinge = BaselineModel(kernel='linear',loss_name='hinge')\n",
        "baseline_1_tester = TestProcedure(baseline_linear_hinge)\n",
        "baseline_1_test_results = baseline_1_tester.RunTest(dataset=dataset,sens_attribute='sex')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: sex\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 2.1906 seconds\n",
            "Prediction Accuracy: 76.0034 %\n",
            "DDP Score: 0.4751\n",
            "DEO Score: 0.2676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBUhzonZqKhx",
        "outputId": "dc73adba-cca4-4ff3-e13e-1f2098e069ee"
      },
      "source": [
        "baseline_rbf_hinge = BaselineModel(kernel='linear',loss_name='hinge')\n",
        "baseline_2_tester = TestProcedure(baseline_rbf_hinge)\n",
        "baseline_2_test_results = baseline_2_tester.RunTest(dataset=dataset,sens_attribute='race')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: race\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 2.3579 seconds\n",
            "Prediction Accuracy: 75.8907 %\n",
            "DDP Score: 0.1565\n",
            "DEO Score: 0.0474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7X28nvXX4sN"
      },
      "source": [
        "## Section 5.2.1 Implement Baseline Hyperparameter Grid Search **for Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ktdFfs1ecY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba18d7a-a571-473c-abb3-78862c2e7690"
      },
      "source": [
        "# regularization parameter beta\n",
        "sens_attribute = 'sex'\n",
        "\n",
        "grid_search_model = BaselineModel()\n",
        "\n",
        "beta_params = [0.0001, 0.001, 0.01] # For Linear Kernel\n",
        "gamma_params = [0.01, 0.1, 1] # For RBF Kernel\n",
        "kernel_params = ['linear','rbf']\n",
        "cv_params = {'l2_beta': beta_params,'gamma': gamma_params,'kernel':kernel_params}\n",
        "\n",
        "x_data, y_data, s_data = build_adult_data(dataset, sens_attribute, load_data_size=None)\n",
        "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=1200, shuffle=True)\n",
        "\n",
        "grid_clf = GridSearchCV(grid_search_model,cv_params, cv=4, n_jobs=1, scoring='accuracy')\n",
        "grid_clf.fit(x_train, y_train, s_train = s_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, error_score=nan,\n",
              "             estimator=BaselineModel(gamma=0.1, kernel='linear', l2_beta=0.001,\n",
              "                                     lambda_max=1, loss_name='hinge',\n",
              "                                     max_iter=3000, reason_points=0.5,\n",
              "                                     solver='SCS', verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'gamma': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf'],\n",
              "                         'l2_beta': [0.0001, 0.001, 0.01]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tb_Vl-QO_G8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67858cf3-2fba-4ba6-e4fa-6a4ba60f9b32"
      },
      "source": [
        "grid_clf.cv_results_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([1.36763191, 1.35384762, 1.30098051, 6.68452728, 2.02252877,\n",
              "        1.49610561, 1.36190659, 1.34823275, 1.32608485, 2.12739909,\n",
              "        1.21782416, 1.55948538, 1.35304594, 1.31241286, 1.31354493,\n",
              "        4.03162658, 1.09479094, 1.17045736]),\n",
              " 'mean_score_time': array([0.00315934, 0.00194436, 0.00359088, 0.00649655, 0.00667483,\n",
              "        0.00664741, 0.00294536, 0.00525451, 0.0017938 , 0.00819671,\n",
              "        0.00664759, 0.00677663, 0.00289232, 0.00177342, 0.00180781,\n",
              "        0.01047772, 0.00689691, 0.0066238 ]),\n",
              " 'mean_test_score': array([0.74416667, 0.75166667, 0.745     , 0.74666667, 0.75083333,\n",
              "        0.75083333, 0.74416667, 0.75166667, 0.745     , 0.7625    ,\n",
              "        0.75416667, 0.74833333, 0.74416667, 0.75166667, 0.745     ,\n",
              "        0.76416667, 0.76416667, 0.77083333]),\n",
              " 'param_gamma': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 1, 1, 1, 1, 1, 1],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf',\n",
              "                    'linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf',\n",
              "                    'linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_l2_beta': masked_array(data=[0.0001, 0.001, 0.01, 0.0001, 0.001, 0.01, 0.0001,\n",
              "                    0.001, 0.01, 0.0001, 0.001, 0.01, 0.0001, 0.001, 0.01,\n",
              "                    0.0001, 0.001, 0.01],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.01},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.01}],\n",
              " 'rank_test_score': array([16,  6, 13, 12,  9,  9, 16,  6, 13,  4,  5, 11, 16,  6, 13,  2,  2,\n",
              "         1], dtype=int32),\n",
              " 'split0_test_score': array([0.73666667, 0.76666667, 0.74      , 0.74666667, 0.76333333,\n",
              "        0.75333333, 0.73666667, 0.76666667, 0.74      , 0.76      ,\n",
              "        0.74333333, 0.75666667, 0.73666667, 0.76666667, 0.74      ,\n",
              "        0.75      , 0.76      , 0.76333333]),\n",
              " 'split1_test_score': array([0.74      , 0.74      , 0.74      , 0.74      , 0.74      ,\n",
              "        0.74333333, 0.74      , 0.74      , 0.74      , 0.76      ,\n",
              "        0.75      , 0.73666667, 0.74      , 0.74      , 0.74      ,\n",
              "        0.75      , 0.75      , 0.74      ]),\n",
              " 'split2_test_score': array([0.74333333, 0.74333333, 0.74333333, 0.74333333, 0.74333333,\n",
              "        0.75      , 0.74333333, 0.74333333, 0.74333333, 0.77333333,\n",
              "        0.76666667, 0.74333333, 0.74333333, 0.74333333, 0.74333333,\n",
              "        0.77333333, 0.76666667, 0.78      ]),\n",
              " 'split3_test_score': array([0.75666667, 0.75666667, 0.75666667, 0.75666667, 0.75666667,\n",
              "        0.75666667, 0.75666667, 0.75666667, 0.75666667, 0.75666667,\n",
              "        0.75666667, 0.75666667, 0.75666667, 0.75666667, 0.75666667,\n",
              "        0.78333333, 0.78      , 0.8       ]),\n",
              " 'std_fit_time': array([0.21366529, 0.20084953, 0.15698018, 5.28617573, 0.27919298,\n",
              "        0.14490268, 0.17094591, 0.21763098, 0.12676309, 0.31910215,\n",
              "        0.07818546, 0.07862485, 0.22198534, 0.19871763, 0.16610186,\n",
              "        0.50397369, 0.04511052, 0.01636168]),\n",
              " 'std_score_time': array([1.97726992e-03, 1.42406399e-04, 3.03552352e-03, 5.63759119e-05,\n",
              "        1.11642221e-05, 6.83861158e-05, 1.97743750e-03, 2.00498420e-03,\n",
              "        5.00663050e-05, 1.40462669e-03, 2.02949605e-04, 4.70136996e-04,\n",
              "        1.96341566e-03, 2.33208076e-05, 1.48868540e-04, 4.06845473e-03,\n",
              "        7.29768453e-04, 2.91000906e-04]),\n",
              " 'std_test_score': array([0.00759203, 0.01067187, 0.00687184, 0.0062361 , 0.00953794,\n",
              "        0.00493007, 0.00759203, 0.01067187, 0.00687184, 0.00640095,\n",
              "        0.00862007, 0.00866025, 0.00759203, 0.01067187, 0.00687184,\n",
              "        0.01460118, 0.01089725, 0.02203217])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi8pObrToe5k"
      },
      "source": [
        "## Section 5.2.2 Implement Baseline Hyperparameter Grid Search **for DDP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3wbd6-RuB8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a55c0c3-de8c-4d24-b899-55499ba8b796"
      },
      "source": [
        "from sklearn.metrics.scorer import make_scorer"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR-Dw7NJr9W_"
      },
      "source": [
        "grid_split_counter = 1\n",
        "def get_positive_rate(y_predicted, y_true):\n",
        "  \n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_predicted).ravel()\n",
        "  pr = (tp+fp) / (tp+fp+tn+fn)\n",
        "  return pr\n",
        "\n",
        "def DDP_Grid_Scoring(y_true,y_predicted,sens_attr,size):\n",
        "  global grid_split_counter\n",
        "  chunk_size = 1200/size\n",
        "  sens_attribute = sens_attr[int((grid_split_counter - 1)*chunk_size): int(grid_split_counter*chunk_size)]\n",
        "  if grid_split_counter == size:\n",
        "    grid_split_counter = 1\n",
        "  else:\n",
        "    grid_split_counter += 1\n",
        "  positive_rate_prot = get_positive_rate(y_predicted[sens_attribute==-1], y_true[sens_attribute==-1])\n",
        "  positive_rate_unprot = get_positive_rate(y_predicted[sens_attribute==1], y_true[sens_attribute==1])\n",
        "  DDP = abs(positive_rate_unprot - positive_rate_prot)\n",
        "  return DDP\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjlXeTgjRNkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ea0f87-8dbe-40bf-e637-bf01ccdcac27"
      },
      "source": [
        "# regularization parameter beta\n",
        "sens_attribute = 'sex'\n",
        "size = 4\n",
        "\n",
        "grid_search_model = BaselineModel()\n",
        "\n",
        "beta_params = [0.0001, 0.001, 0.01] # For Linear Kernel\n",
        "gamma_params = [0.01, 0.1, 1] # For RBF Kernel\n",
        "kernel_params = ['linear','rbf']\n",
        "cv_params = {'l2_beta': beta_params,'gamma': gamma_params,'kernel':kernel_params}\n",
        "\n",
        "x_data, y_data, s_data = build_adult_data(dataset,sens_attribute,load_data_size=None)\n",
        "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=1200, shuffle=True)\n",
        "\n",
        "\n",
        "DDP_scorer = make_scorer(DDP_Grid_Scoring, greater_is_better=False, sens_attr = s_train, size = size)\n",
        "\n",
        "fairness_grid_clf = GridSearchCV(grid_search_model,cv_params, cv=size, n_jobs=1, scoring=DDP_scorer)\n",
        "fairness_grid_clf.fit(x_train, y_train, s_train = s_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, error_score=nan,\n",
              "             estimator=BaselineModel(gamma=0.1, kernel='linear', l2_beta=0.001,\n",
              "                                     lambda_max=1, loss_name='hinge',\n",
              "                                     max_iter=3000, reason_points=0.5,\n",
              "                                     solver='SCS', verbose=False),\n",
              "             iid='deprecated', n_jobs=1,\n",
              "             param_grid={'gamma': [0.01, 0.1, 1], 'kernel': ['linear', 'rbf'],\n",
              "                         'l2_beta': [0.0001, 0.001, 0.01]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=make_scorer(DDP_Grid_Scoring, greater_is_better=False, sens_attr=[-1  1  1 ... -1  1  1], size=4),\n",
              "             verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSweey0Jtw88",
        "outputId": "4f48a547-1dbf-4e7d-a898-b4de27e851a4"
      },
      "source": [
        "fairness_grid_clf.cv_results_"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([1.83912915, 1.96422827, 1.64278579, 3.31208575, 1.64253575,\n",
              "        1.36922288, 1.84730655, 1.90828186, 1.65270257, 2.28181803,\n",
              "        1.23116511, 1.63804889, 1.82962102, 1.914334  , 1.65671676,\n",
              "        3.41453904, 1.12276918, 1.17795652]),\n",
              " 'mean_score_time': array([0.00461262, 0.00432265, 0.00439888, 0.00959873, 0.00973868,\n",
              "        0.01436234, 0.00668746, 0.00555092, 0.00457966, 0.01136094,\n",
              "        0.01722443, 0.00903273, 0.00557387, 0.0070951 , 0.00427979,\n",
              "        0.00983602, 0.00904304, 0.01021135]),\n",
              " 'mean_test_score': array([-0.44712934, -0.42379601, -0.44824046, -0.42046268, -0.43745621,\n",
              "        -0.41671575, -0.44712934, -0.42379601, -0.44824046, -0.35764221,\n",
              "        -0.35175878, -0.41836012, -0.44712934, -0.42379601, -0.44824046,\n",
              "        -0.33226122, -0.33184235, -0.34937799]),\n",
              " 'param_gamma': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
              "                    0.1, 0.1, 1, 1, 1, 1, 1, 1],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf',\n",
              "                    'linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf',\n",
              "                    'linear', 'linear', 'linear', 'rbf', 'rbf', 'rbf'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_l2_beta': masked_array(data=[0.0001, 0.001, 0.01, 0.0001, 0.001, 0.01, 0.0001,\n",
              "                    0.001, 0.01, 0.0001, 0.001, 0.01, 0.0001, 0.001, 0.01,\n",
              "                    0.0001, 0.001, 0.01],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.01, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.01, 'kernel': 'rbf', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.1, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 0.1, 'kernel': 'rbf', 'l2_beta': 0.01},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.0001},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.001},\n",
              "  {'gamma': 1, 'kernel': 'linear', 'l2_beta': 0.01},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.0001},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.001},\n",
              "  {'gamma': 1, 'kernel': 'rbf', 'l2_beta': 0.01}],\n",
              " 'rank_test_score': array([13,  9, 16,  8, 12,  6, 13,  9, 16,  5,  4,  7, 13,  9, 16,  2,  1,\n",
              "         3], dtype=int32),\n",
              " 'split0_test_score': array([-0.40873016, -0.40873016, -0.40873016, -0.40873016, -0.40873016,\n",
              "        -0.3531746 , -0.40873016, -0.40873016, -0.40873016, -0.33465608,\n",
              "        -0.33333333, -0.40873016, -0.40873016, -0.40873016, -0.40873016,\n",
              "        -0.29761905, -0.31150794, -0.28174603]),\n",
              " 'split1_test_score': array([-0.53305861, -0.53305861, -0.53305861, -0.53305861, -0.55686082,\n",
              "        -0.53939357, -0.53305861, -0.53305861, -0.53305861, -0.45839228,\n",
              "        -0.4321914 , -0.54714312, -0.53305861, -0.53305861, -0.53305861,\n",
              "        -0.40642106, -0.41613875, -0.47050864]),\n",
              " 'split2_test_score': array([-0.4556175 , -0.4556175 , -0.4556175 , -0.4556175 , -0.45090051,\n",
              "        -0.41873928, -0.4556175 , -0.4556175 , -0.4556175 , -0.29974271,\n",
              "        -0.37928816, -0.45090051, -0.4556175 , -0.4556175 , -0.4556175 ,\n",
              "        -0.31389365, -0.30638937, -0.32525729]),\n",
              " 'split3_test_score': array([-0.39111111, -0.29777778, -0.39555556, -0.28444444, -0.33333333,\n",
              "        -0.35555556, -0.39111111, -0.29777778, -0.39555556, -0.33777778,\n",
              "        -0.26222222, -0.26666667, -0.39111111, -0.29777778, -0.39555556,\n",
              "        -0.31111111, -0.29333333, -0.32      ]),\n",
              " 'std_fit_time': array([1.30733547, 1.48519339, 0.96454073, 0.45527874, 0.26782146,\n",
              "        0.11839256, 1.26327052, 1.44640942, 1.0156187 , 0.16652719,\n",
              "        0.05256057, 0.13255223, 1.30136547, 1.45155452, 1.01476878,\n",
              "        0.7333104 , 0.0552348 , 0.0569893 ]),\n",
              " 'std_score_time': array([3.75905788e-04, 4.43014505e-05, 1.90475360e-04, 5.19842776e-04,\n",
              "        1.35753794e-03, 5.51630864e-03, 2.46462854e-03, 1.89487839e-03,\n",
              "        3.97185621e-04, 4.28726002e-03, 4.78161317e-03, 1.55757874e-04,\n",
              "        1.87037194e-03, 2.96205503e-03, 3.87481081e-05, 1.18416362e-03,\n",
              "        1.35236030e-04, 2.19975955e-03]),\n",
              " 'std_test_score': array([0.0549282 , 0.08523277, 0.05381752, 0.0902113 , 0.08078516,\n",
              "        0.07555129, 0.0549282 , 0.08523277, 0.05381752, 0.0600539 ,\n",
              "        0.06241708, 0.10093015, 0.0549282 , 0.08523277, 0.05381752,\n",
              "        0.04325638, 0.04911764, 0.07192286])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UxXTvGhUezC"
      },
      "source": [
        "## Section 5.3 Implement Lohaus' SearchFair Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIvoGBIdIBv3"
      },
      "source": [
        "class SearchFair(BaseEstimator):\n",
        "    \"\"\"SearchFair\n",
        "    Parameters\n",
        "    ----------\n",
        "    fairness_notions: string\n",
        "        The name of the fairness notion that the classifier should respect. 'DDP' or 'DEO' can be used.\n",
        "    fairness_regularizer: string\n",
        "        The name of the fairness relaxation that is used as a regularizer. It can be 'linear', or 'wu'. For 'wu', the 'wu_bound' can be chosen.\n",
        "    wu_bound: string\n",
        "        The name of the function that is used in the bounds of Wu et al. It can be 'hinge', 'logistic', 'squared', 'exponential'\n",
        "    reg_beta: float\n",
        "        Regularization parameter Beta for the l2 regularization.\n",
        "    kernel: string\n",
        "        The kind of kernel that is used. It can be 'linear', 'rbf' or 'poly'. For 'rbf' and 'poly', the parameter gamma can be used.\n",
        "    gamma: float\n",
        "        For kernel='rbf', gamma is the kernel width, for kernel='poly', gamma is the degree.\n",
        "    loss_name: string\n",
        "        The name of the loss used. Possible values: 'hinge', 'logistic', 'squared', 'exponential'\n",
        "    lambda_max: float\n",
        "        The value of lambda_max for the start of the binary search.\n",
        "    max_iter: int\n",
        "        The number of iterations of the solver chosen.\n",
        "    reason_points: float\n",
        "        The ratio of points used as reasonable points for the similarity-based approach of SearchFair.\n",
        "    stop_criterion: float\n",
        "        If SearchFair finds a classifier that is at least as fair as 'stop_criterion', than it stops the search.\n",
        "    max_search_iter: int\n",
        "        The number of iterations for the binary search.\n",
        "    solver: string\n",
        "        The solver that is used by cvxpy. It can be 'SCS' or 'ECOS'.\n",
        "    verbose: boolean\n",
        "    Attributes\n",
        "    ----------\n",
        "    coef_: numpy array\n",
        "        An array containing the trained weights for each reasonable point.\n",
        "    reason_pts_index: numpy array\n",
        "        An array containing the indices of the reasonable points in the training data.\n",
        "    Notes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fairness_notion='DDP', fairness_regularizer='wu', wu_bound='hinge', reg_beta=0.001, kernel='linear', gamma=None, loss_name='hinge', lambda_max=1, max_iter=3000, reason_points=0.5, stop_criterion=0.01, max_search_iter=10, solver='SCS', verbose=False):\n",
        "\n",
        "        self.reg_beta = reg_beta\n",
        "        self.fairness_notion = fairness_notion\n",
        "        self.max_iter = max_iter\n",
        "        self.max_search_iter = max_search_iter\n",
        "        self.solver = solver\n",
        "        self.verbose = verbose\n",
        "        self.stop_criterion = stop_criterion\n",
        "        self.reason_points = reason_points\n",
        "        self.lambda_max = lambda_max\n",
        "        self.wu_bound = wu_bound\n",
        "        self.fairness_regularizer = fairness_regularizer\n",
        "        self.wu_bound = wu_bound\n",
        "        self.gamma = gamma\n",
        "        self.loss_name = loss_name\n",
        "        self.kernel = kernel\n",
        "\n",
        "    def fit(self, x_train, y_train, s_train=None):\n",
        "        \"\"\"Fits SearchFair on the given training data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x_train: numpy array\n",
        "            The features of the training data with shape=(number_points,number_features).\n",
        "        y_train: numpy array\n",
        "            The class labels of the training data with shape=(number_points,).\n",
        "        s_train: numpy array\n",
        "            The binary sensitive attributes of the training data with shape=(number_points,).\n",
        "        Returns\n",
        "        ----------\n",
        "        self: object\n",
        "        \"\"\"\n",
        "\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.s_train = s_train\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Preprocessing...\")\n",
        "        self._preprocess()\n",
        "\n",
        "        lbda_min, lbda_max = 0, self.lambda_max\n",
        "\n",
        "        def learn(reg, bound='upper'):\n",
        "            # If bound is None, we have decided which one to use, and we are in the middle of the binary search\n",
        "\n",
        "            self.fairness_lambda = reg\n",
        "            if bound is not None:\n",
        "                self._construct_problem(bound=bound)\n",
        "            self._optimize()\n",
        "            DDP, DEO = self.compute_fairness_measures(self.predict(x_train), y_train, s_train)\n",
        "            if self.fairness_notion == 'DDP':\n",
        "                fair_value = DDP\n",
        "            else:\n",
        "                fair_value = DEO\n",
        "            if self.verbose: print(\"Obtained:\",self.fairness_notion, \"= %0.4f with lambda = %0.4f\" % (fair_value, reg))\n",
        "            return fair_value, self.coef_.copy()\n",
        "\n",
        "        criterion = False\n",
        "\n",
        "        bound = 'upper' # even though an upper bound is specified, since lambda_min is 0, it falls away\n",
        "        if self.verbose: print(\"Testing lambda_min: %0.2f\" % lbda_min)\n",
        "        min_fair_measure, min_alpha = learn(lbda_min, bound=bound)\n",
        "        if np.sign(min_fair_measure) < 0: bound = 'lower'\n",
        "        if self.verbose: print(\"Testing lambda_max: %0.2f\" % lbda_max)\n",
        "        max_fair_measure, max_alpha = learn(lbda_max, bound)\n",
        "\n",
        "        if np.abs(min_fair_measure) < np.abs(max_fair_measure):\n",
        "            best_lbda, best_fair_measure = lbda_min, min_fair_measure\n",
        "            best_alpha = min_alpha\n",
        "        else:\n",
        "            best_lbda, best_fair_measure = lbda_max, max_fair_measure\n",
        "            best_alpha = max_alpha\n",
        "        if  np.abs(best_fair_measure) < self.stop_criterion:\n",
        "            print(\"Classifier is fair enough with lambda = {:.4f}\".format(best_lbda))\n",
        "        elif np.sign(min_fair_measure) == np.sign(max_fair_measure):\n",
        "            print('Fairness value has the same sign for lambda_min and lambda_max.')\n",
        "            print('Either try a different fairness regularizer or change the values of lambda_min and lambda_max') # Possibly, there could be a few more tries by reducing lambda.\n",
        "        else:\n",
        "            search_iter = 0\n",
        "            if self.verbose: print(\"Starting Binary Search...\")\n",
        "            while not criterion and search_iter < self.max_search_iter:\n",
        "                lbda_new = (lbda_min + lbda_max) / 2\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(10*'-'+\"Iteration #%0.0f\" % search_iter + 10*'-')\n",
        "                    print(\"Testing new Lambda: %0.4f\" % lbda_new)\n",
        "\n",
        "                new_rd, new_alpha = learn(lbda_new, None)\n",
        "                if np.abs(new_rd) < np.abs(best_fair_measure):\n",
        "                    best_fair_measure = new_rd\n",
        "                    best_lbda = lbda_new\n",
        "                    best_alpha = new_alpha.copy()\n",
        "\n",
        "                if np.sign(new_rd) == np.sign(min_fair_measure):\n",
        "                    min_fair_measure = new_rd\n",
        "                    lbda_min = lbda_new\n",
        "                else:\n",
        "                    max_fair_measure = new_rd\n",
        "                    lbda_max = lbda_new\n",
        "                if np.abs(new_rd) < self.stop_criterion:\n",
        "                    criterion = True\n",
        "\n",
        "                search_iter += 1\n",
        "            if search_iter==self.max_search_iter and self.verbose:\n",
        "                print(\"Hit maximum iterations of Binary Search.\")\n",
        "            elif self.verbose:\n",
        "                print(\"Sufficient fairness obtained before maximum iterations were reached.\")\n",
        "\n",
        "        if self.verbose: print(10*'-'+\"Found Lambda %0.4f with fairness %0.4f\" % (best_lbda, best_fair_measure)+10*'-')\n",
        "        self.coef_ = best_alpha.copy()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        \"\"\"Predict the label of test data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x_test: numpy array\n",
        "            The features of the test data with shape=(number_points,number_features).\n",
        "        Returns\n",
        "        ----------\n",
        "        y_hat: numpy array\n",
        "            The predicted class labels with shape=(number_points,).\n",
        "        \"\"\"\n",
        "        kernel_matr = self.kernel_function(x_test, self.x_train[self.reason_pts_index])\n",
        "        y_hat = np.dot(self.coef_, np.transpose(kernel_matr))\n",
        "        return np.sign(y_hat)\n",
        "\n",
        "    def _preprocess(self):\n",
        "        \"\"\"Setting the attributes loss_func, kernel_function, and weight_vector,\n",
        "        which depends on the fairness notion, and is used in fairness related objects.\n",
        "        \"\"\"\n",
        "        self.coef_ = None\n",
        "        self.fairness_lambda = 0\n",
        "        if self.loss_name == 'logistic':\n",
        "            self.loss_func = lambda z: cp.logistic(-z)\n",
        "        elif self.loss_name == 'hinge':\n",
        "            self.loss_func = lambda z: cp.pos(1.0 - z)\n",
        "        elif self.loss_name == 'squared':\n",
        "            self.loss_func = lambda z: cp.square(-z)\n",
        "        elif self.loss_name == 'exponential':\n",
        "            self.loss_func = lambda z: cp.exp(-z)\n",
        "        else:\n",
        "            print('Using default loss: hinge loss.')\n",
        "            self.loss_func = lambda z: cp.pos(1.0 - z)\n",
        "\n",
        "        if self.kernel == 'rbf':\n",
        "            self.kernel_function = lambda X, Y: kernels.rbf_kernel(X, Y, self.gamma)\n",
        "        elif self.kernel == 'poly':\n",
        "            self.kernel_function = lambda X, Y: kernels.polynomial_kernel(X, Y, degree=self.gamma)\n",
        "        elif self.kernel == 'linear':\n",
        "            self.kernel_function = lambda X, Y: kernels.linear_kernel(X, Y) + 1\n",
        "        else:\n",
        "            self.kernel_function = kernel\n",
        "\n",
        "        if self.wu_bound == 'logistic':\n",
        "            self.cvx_kappa = lambda z: cp.logistic(z)\n",
        "            self.cvx_delta = lambda z: 1 - cp.logistic(-z)\n",
        "        elif self.wu_bound == 'hinge':\n",
        "            self.cvx_kappa = lambda z: cp.pos(1 + z)\n",
        "            self.cvx_delta = lambda z: 1 - cp.pos(1 - z)\n",
        "        elif self.wu_bound == 'squared':\n",
        "            self.cvx_kappa = lambda z: cp.square(1 + z)\n",
        "            self.cvx_delta = lambda z: 1 - cp.square(1 - z)\n",
        "        elif self.wu_bound == 'exponential':\n",
        "            self.cvx_kappa = lambda z: cp.exp(z)\n",
        "            self.cvx_delta = lambda z: 1 - cp.exp(-z)\n",
        "        else:\n",
        "            print('Using default bound with hinge.')\n",
        "            self.cvx_kappa = lambda z: cp.pos(1 + z)\n",
        "            self.cvx_delta = lambda z: 1 - cp.pos(1 - z)\n",
        "\n",
        "        self.nmb_pts = len(self.s_train)\n",
        "        self.nmb_unprotected = np.sum(self.s_train == 1)\n",
        "        self.prob_unprot = self.nmb_unprotected / self.nmb_pts\n",
        "        self.prob_prot = 1 - self.prob_unprot\n",
        "\n",
        "        self.nmb_pos = np.sum(self.y_train == 1)\n",
        "        self.nmb_prot_pos = np.sum(self.y_train[self.s_train == -1] == 1)\n",
        "        self.prob_prot_pos = self.nmb_prot_pos / self.nmb_pos\n",
        "        self.prob_unprot_pos = 1 - self.prob_prot_pos\n",
        "\n",
        "        # Create weights that are necessary for the fairness constraint\n",
        "        if self.fairness_notion == 'DDP':\n",
        "            normalizer = self.nmb_pts\n",
        "            self.weight_vector = np.array(\n",
        "                [1.0 / self.prob_prot if self.s_train[i] == -1 else 1.0 / self.prob_unprot for i in range(len(self.s_train))]).reshape(-1,1)\n",
        "            self.weight_vector = (1 / normalizer) * self.weight_vector\n",
        "        elif self.fairness_notion == 'DEO':\n",
        "            normalizer = self.nmb_pos\n",
        "            self.weight_vector = np.array(\n",
        "                [1.0 / self.prob_prot_pos if self.s_train[i] == -1 else 1.0 / self.prob_unprot_pos for i in range(len(self.s_train))]).reshape(-1, 1)\n",
        "            self.weight_vector = 0.5 * (self.y_train.reshape(-1, 1) + 1) * self.weight_vector\n",
        "            self.weight_vector = (1 / normalizer) * self.weight_vector\n",
        "\n",
        "        # Choose random reasonable points\n",
        "        if self.reason_points <= 1:\n",
        "            self.reason_pts_index = list(range(int(self.nmb_pts * self.reason_points)))\n",
        "        else:\n",
        "            self.reason_pts_index = list(range(self.reason_points))\n",
        "        self.nmb_reason_pts = len(self.reason_pts_index)\n",
        "\n",
        "    def _construct_problem(self, bound='upper'):\n",
        "        \"\"\" Construct the cvxpy minimization problem.\n",
        "        It depends on the fairness regularizer chosen.\n",
        "        \"\"\"\n",
        "\n",
        "        # Variable to optimize\n",
        "        self.alpha_var = cp.Variable((len(self.reason_pts_index), 1))\n",
        "        # Parameter for Kernel Matrix\n",
        "        self.kernel_matrix = cp.Parameter(shape=(self.x_train.shape[0], len(self.reason_pts_index)))\n",
        "        self.fair_reg_cparam = cp.Parameter(nonneg=True)\n",
        "\n",
        "\n",
        "        # Form SVM with L2 regularization\n",
        "        if self.fairness_lambda == 0:\n",
        "            self.loss = cp.sum(self.loss_func(cp.multiply(self.y_train.reshape(-1, 1), self.kernel_matrix @ self.alpha_var))) + self.reg_beta * self.nmb_pts * cp.square(\n",
        "                cp.norm(self.alpha_var, 2))\n",
        "        else:\n",
        "            sy_hat = cp.multiply(self.s_train.reshape(-1, 1), self.kernel_matrix @ self.alpha_var)\n",
        "\n",
        "            if self.fairness_regularizer == 'wu':\n",
        "                if bound == 'upper':\n",
        "                    fairness_relaxation = cp.sum(cp.multiply(self.weight_vector, self.cvx_kappa(sy_hat))) - 1\n",
        "                else:\n",
        "                    fairness_relaxation = -1 * cp.sum(cp.multiply(self.weight_vector, self.cvx_delta(sy_hat))) - 1\n",
        "\n",
        "\n",
        "            elif self.fairness_regularizer == 'linear':\n",
        "                if bound == 'upper':\n",
        "                    fairness_relaxation = cp.sum(cp.multiply(self.weight_vector, self.kernel_matrix @ self.alpha_var))\n",
        "                else:\n",
        "                    fairness_relaxation = -1 * cp.sum(cp.multiply(self.weight_vector, self.kernel_matrix @ self.alpha_var))\n",
        "\n",
        "            if self.reg_beta == 0:\n",
        "                self.loss = (1/self.nmb_pts) * cp.sum(self.loss_func(cp.multiply(self.y_train.reshape(-1, 1), self.kernel_matrix @ self.alpha_var))) + \\\n",
        "                                self.fair_reg_cparam * fairness_relaxation\n",
        "            else:\n",
        "                self.loss = (1 / self.nmb_pts) * cp.sum(self.loss_func(cp.multiply(self.y_train.reshape(-1, 1), self.kernel_matrix @ self.alpha_var))) + \\\n",
        "                            self.fair_reg_cparam * fairness_relaxation + self.reg_beta * cp.square(cp.norm(self.alpha_var, 2))\n",
        "\n",
        "        self.prob = cp.Problem(cp.Minimize(self.loss))\n",
        "\n",
        "    def _optimize(self):\n",
        "        \"\"\"Conduct the optimization of the created problem by using ECOS or SCS\n",
        "        with cvxpy. \n",
        "        \"\"\"\n",
        "\n",
        "        # Compute and initialize kernel matrix\n",
        "        self.K_sim = self.kernel_function(self.x_train, self.x_train[self.reason_pts_index])\n",
        "        self.kernel_matrix.value = self.K_sim\n",
        "        self.fair_reg_cparam.value = self.fairness_lambda\n",
        "\n",
        "        if self.verbose == 2:\n",
        "            verbose = True\n",
        "        else:\n",
        "            verbose = False\n",
        "        if self.solver == 'SCS':\n",
        "            self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=verbose, warm_start=True)\n",
        "        elif self.solver == 'ECOS':\n",
        "            try:\n",
        "                self.prob.solve(solver=cp.ECOS, max_iters=self.max_iter, verbose=verbose, warm_start=True)\n",
        "            except Exception as e:\n",
        "                self.prob.solve(solver=cp.SCS, max_iters=self.max_iter, verbose=verbose, warm_start=True)\n",
        "        if verbose:\n",
        "            print('status %s ' % self.prob.status)\n",
        "            print('value %s ' % self.prob.value)\n",
        "        self.coef_ = self.alpha_var.value.squeeze()\n",
        "    def compute_fairness_measures(self, y_predicted, y_true, sens_attr):\n",
        "        \"\"\"Compute value of demographic parity and equality of opportunity for given predictions.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        sens_attr: numpy array\n",
        "            The sensitive labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ----------\n",
        "        DDP: float\n",
        "            The difference of demographic parity.\n",
        "        DEO: float\n",
        "            The difference of equality of opportunity.\n",
        "        \"\"\"\n",
        "        positive_rate_prot = self.get_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        positive_rate_unprot = self.get_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        true_positive_rate_prot = self.get_true_positive_rate(y_predicted[sens_attr==-1], y_true[sens_attr==-1])\n",
        "        true_positive_rate_unprot = self.get_true_positive_rate(y_predicted[sens_attr==1], y_true[sens_attr==1])\n",
        "        DDP = positive_rate_unprot - positive_rate_prot\n",
        "        DEO = true_positive_rate_unprot - true_positive_rate_prot\n",
        "\n",
        "        return DDP, DEO\n",
        "\n",
        "    def get_positive_rate(self, y_predicted, y_true):\n",
        "        \"\"\"Compute the positive rate for given predictions of the class label.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ---------\n",
        "        pr: float\n",
        "            The positive rate.\n",
        "        \"\"\"\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_predicted).ravel()\n",
        "        pr = (tp+fp) / (tp+fp+tn+fn)\n",
        "        return pr\n",
        "\n",
        "    def get_true_positive_rate(self, y_predicted, y_true):\n",
        "        \"\"\"Compute the true positive rate for given predictions of the class label.\n",
        "        Parameters\n",
        "        ----------\n",
        "        y_predicted: numpy array\n",
        "            The predicted class labels of shape=(number_points,).\n",
        "        y_true: numpy array\n",
        "            The true class labels of shape=(number_points,).\n",
        "        Returns\n",
        "        ---------\n",
        "        tpr: float\n",
        "            The true positive rate.\n",
        "        \"\"\"\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_predicted).ravel()\n",
        "        tpr = tp / (tp+fn)\n",
        "        return tpr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4AyLJ9cbL57"
      },
      "source": [
        "# Section 6\tResults & Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhM0k8dGWXnv"
      },
      "source": [
        "### DDP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-HDdM5nWMDz",
        "outputId": "a2d73d00-173e-4e43-95ed-967d4af308f7"
      },
      "source": [
        "fairness_notion = 'DDP'  \n",
        "kernel = 'linear' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Sex_DDP_LinearKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Sex_DDP_LinearKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='sex')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: sex\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 153.3624 seconds\n",
            "Prediction Accuracy: 63.606 %\n",
            "DDP Score: 0.0463\n",
            "DEO Score: 0.007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hVkv3KGYYhQ",
        "outputId": "d9117538-c508-4060-dc6b-94d70ef987aa"
      },
      "source": [
        "fairness_notion = 'DDP'  \n",
        "kernel = 'linear' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Race_DDP_LinearKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Race_DDP_LinearKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='race')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: race\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 35.5928 seconds\n",
            "Prediction Accuracy: 72.3415 %\n",
            "DDP Score: 0.0132\n",
            "DEO Score: -0.063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hkOTxQPbKGO",
        "outputId": "685645a2-7cb2-420e-9641-04e8d3f04b17"
      },
      "source": [
        "fairness_notion = 'DDP'  \n",
        "kernel = 'rbf' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Sex_DDP_RBFKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Sex_DDP_RBFKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='sex')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: sex\n",
            "Kernel Type: rbf\n",
            "Loss Func: hinge\n",
            "Run Time: 40.9092 seconds\n",
            "Prediction Accuracy: 62.9972 %\n",
            "DDP Score: -0.0015\n",
            "DEO Score: -0.0765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Uf2WtQb6Mr",
        "outputId": "7546f91c-b662-486b-e501-2fb076914ffe"
      },
      "source": [
        "fairness_notion = 'DDP'  \n",
        "kernel = 'rbf' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Race_DDP_RBFKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Race_DDP_RBFKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='race')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: race\n",
            "Kernel Type: rbf\n",
            "Loss Func: hinge\n",
            "Run Time: 60.2459 seconds\n",
            "Prediction Accuracy: 73.5636 %\n",
            "DDP Score: 0.0333\n",
            "DEO Score: -0.0509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGQvBb4rWZmg"
      },
      "source": [
        "### DEO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbJ9K7HjcMjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f2e688-9041-4a36-cf93-d2003f4064a7"
      },
      "source": [
        "fairness_notion = 'DEO'  \n",
        "kernel = 'linear' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Sex_DEO_LinearKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Sex_DEO_LinearKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='sex')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: sex\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 73.1433 seconds\n",
            "Prediction Accuracy: 70.8217 %\n",
            "DDP Score: 0.1641\n",
            "DEO Score: 0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6xPFkuCWjMO",
        "outputId": "e2b40630-af86-4fd8-ee6c-2abacc234626"
      },
      "source": [
        "fairness_notion = 'DEO'  \n",
        "kernel = 'linear' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Race_DEO_LinearKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Race_DEO_LinearKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='race')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: race\n",
            "Kernel Type: linear\n",
            "Loss Func: hinge\n",
            "Run Time: 72.2128 seconds\n",
            "Prediction Accuracy: 75.8546 %\n",
            "DDP Score: 0.1556\n",
            "DEO Score: 0.0416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duvFzsrdWnbV",
        "outputId": "88b14ccf-235b-4d2f-b4fd-34ed886cf735"
      },
      "source": [
        "fairness_notion = 'DEO'  \n",
        "kernel = 'rbf' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Sex_DEO_RBFKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Sex_DEO_RBFKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='sex')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: sex\n",
            "Kernel Type: rbf\n",
            "Loss Func: hinge\n",
            "Run Time: 45.8727 seconds\n",
            "Prediction Accuracy: 71.8544 %\n",
            "DDP Score: 0.2551\n",
            "DEO Score: -0.0035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3WSFZX1Wnmd",
        "outputId": "bd422dfb-6e85-48a1-cf1d-07b2c0cb69d6"
      },
      "source": [
        "fairness_notion = 'DEO'  \n",
        "kernel = 'rbf' \n",
        "verbose = False\n",
        "\n",
        "SearchFair_Race_DEO_RBFKernel_Hinge = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
        "SearchFair_tester = TestProcedure(SearchFair_Race_DEO_RBFKernel_Hinge)\n",
        "SearchFair_tester_results = SearchFair_tester.RunTest(dataset=dataset,sens_attribute='race')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitive Attribute: race\n",
            "Kernel Type: rbf\n",
            "Loss Func: hinge\n",
            "Run Time: 59.6657 seconds\n",
            "Prediction Accuracy: 76.6393 %\n",
            "DDP Score: 0.1444\n",
            "DEO Score: 0.035\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}